{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projective Preferential Bayesian Optimization: DSGE prior elicitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">In this notebook the expert knowledge about DSGE priors can be elicited by using the [Projective Preferential Bayesian Optimization](https://arxiv.org/abs/2002.03113) framework. The test case is the New Keynesian sticky price model of Calvo (1983). </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.getcwd()+'/src')\n",
    "sys.path.insert(1, os.getcwd()+'/dsge')\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from gp_model import GPModel\n",
    "from ppbo_settings import PPBO_settings\n",
    "from acquisition import next_query\n",
    "from gui import GUI_session\n",
    "from jupyter_ui_poll import run_ui_poll_loop\n",
    "from ipywidgets.widgets import HBox\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 60em; }</style>\")) #Make outputwindow larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the aquisition strategy and the problem setting\n",
    "Acquisition startegies with unit projections ($\\boldsymbol{\\xi}$ is an unit vector):\n",
    "- PCD = preferential coordinate descent\n",
    "- EI-EXT = same as EI-FIXEDX except only unit projections are allowed\n",
    "- EI-EXT-FAST = same as EI-EXT except $d\\mathbf{x}$ integral omitted\n",
    "- EI-VARMAX = same as EI-EXT except $\\mathbf{x}$ is chosen to maximize GP variance\n",
    "- EI-VARMAX-FAST = same as EI-VARMAX except $d\\mathbf{x}$ integral omitted\n",
    "\n",
    "Acquisition startegies with non-unit projections:\n",
    "- EI = expected improvement by projective preferential query\n",
    "- EI-FIXEDX = same as EI except $\\mathbf{x}$ is fixed to $\\textrm{argmax}_{\\mathbf{x}}\\mu(\\mathbf{x})$ (xstar)\n",
    "- EXT = pure exploitation\n",
    "- EXR = pure exploration (variance maximization)\n",
    "- RAND = random \n",
    "\n",
    "'user_feedback_grid_size' determines the granularity of the slider, that is, the number of options available for the user. Each option is run in a dedicated CPU. Hence, the optimal performance will be achieved if 'user_feedback_grid_size' is a multiple of the number of CPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_strategy = 'PCD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPBOset = PPBO_settings(D=7,bounds=((0.2,0.8),(0.2,0.8),(0.2,0.8),(0.2,0.8),(2,15),(0.25,3),(0.3,0.9)),\n",
    "                    xi_acquisition_function=acquisition_strategy,user_feedback_grid_size=7,\n",
    "                    theta_initial=[0.09,0.2,0.35],verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set initial queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_queries_xi = np.diag([PPBOset.original_bounds[i][1] for i in range(PPBOset.D)])\n",
    "initial_queries_x = np.random.uniform([PPBOset.original_bounds[i][0] for i in range(PPBOset.D)], [PPBOset.original_bounds[i][1] for i in range(PPBOset.D)], (len(initial_queries_xi), PPBOset.D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_QUERIES = 1\n",
    "ADAPTIVE_INITIALIZATION = True  #In initilization: immediatly update the coordinate according to the user feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZE_HYPERPARAMETERS_AFTER_EACH_ITERATION = False\n",
    "OPTIMIZE_HYPERPARAMETERS_AFTER_QUERY_NUMBER = 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the user session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_log = False\n",
    "if should_log:\n",
    "    orig_stdout = sys.stdout\n",
    "    log_file = open('dsge/user_session_log_'+str(datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))+'.txt', \"w\")\n",
    "    sys.stdout = log_file\n",
    "GUI_ses = GUI_session(PPBOset)\n",
    "results_mustar = []\n",
    "results_xstar = []\n",
    "results_xstar_unscaled = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elicitation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(initial_queries_xi)+NUMBER_OF_QUERIES):\n",
    "    if i < len(initial_queries_xi):\n",
    "        print(f'Initialization in progress... ({i+1}/{len(initial_queries_xi)})\\r', end=\"\")\n",
    "    else:\n",
    "        print(f'Elicitation in progress... ({i+1-len(initial_queries_xi)}/{NUMBER_OF_QUERIES})\\r', end=\"\")\n",
    "    ''' Next projective preferential query '''\n",
    "    if i < len(initial_queries_xi):\n",
    "        xi = initial_queries_xi[i].copy()\n",
    "        if not i==0 and GUI_ses.user_feedback is not None and ADAPTIVE_INITIALIZATION:\n",
    "            initial_queries_x[i:,:] = GUI_ses.user_feedback\n",
    "        x = initial_queries_x[i].copy()\n",
    "        x[xi!=0] = 0\n",
    "    else:\n",
    "        xi,x = next_query(PPBOset,GP_model,unscale=True)\n",
    "    GUI_ses.set_x(x)\n",
    "    GUI_ses.set_xi(xi)\n",
    "    ''' Event loop '''\n",
    "    button,slider,fig,l1,l2,l3,l4 = GUI_ses.prepare_app()\n",
    "    app = HBox(children=(slider,button))\n",
    "    def wait_user_input():\n",
    "        if not GUI_ses.user_feedback_was_given:\n",
    "            GUI_ses.update_plot(l1,l2,l3,l4,fig,slider)  \n",
    "            return None\n",
    "        app.close()\n",
    "        GUI_ses.user_feedback_was_given = False\n",
    "        GUI_ses.save_results()\n",
    "        return 1       \n",
    "    display(app)\n",
    "    dt = run_ui_poll_loop(wait_user_input)\n",
    "    ''' Create GP model for first time '''\n",
    "    if i==0:\n",
    "        GP_model = GPModel(PPBOset)\n",
    "    ''' Update GP model '''\n",
    "    GP_model.update_feedback_processing_object(np.array(GUI_ses.results))\n",
    "    GP_model.update_data()\n",
    "    GP_model.update_model()\n",
    "    if i+1==OPTIMIZE_HYPERPARAMETERS_AFTER_QUERY_NUMBER:\n",
    "        GP_model.update_model(optimize_theta=True)     \n",
    "    else:\n",
    "        GP_model.update_model(optimize_theta=OPTIMIZE_HYPERPARAMETERS_AFTER_EACH_ITERATION)\n",
    "    ''' Save the predictive mean maximum and maximizer'''\n",
    "    results_mustar.append(GP_model.mustar)\n",
    "    results_xstar.append(GP_model.xstar)\n",
    "    results_xstar_unscaled.append(GP_model.FP.unscale(GP_model.xstar))\n",
    "    clear_output(wait=True)\n",
    "print(\"Elicitation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total time: \" + str(time.time()-start) + \" seconds.\")\n",
    "xstar, mustar, xstars_local  = GP_model.mu_star(mustar_finding_trials=15)\n",
    "xstar_unscaled = GP_model.FP.unscale(xstar)\n",
    "xstars_local_unscaled = np.array([list(GP_model.FP.unscale(x)) for x in xstars_local])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the user session results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results to csv-file\n",
    "print(\"Saving the user session results...\")\n",
    "user_session_results = GUI_ses.results.copy()\n",
    "user_session_results['iter_mustar'] = results_mustar\n",
    "user_session_results['iter_xstar'] = results_xstar\n",
    "user_session_results['iter_xstar_unscaled'] = results_xstar_unscaled\n",
    "user_session_results.to_csv('dsge/user_session_results_'+str(datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))+'.csv',index=False)\n",
    "#Close the log-file\n",
    "if should_log:\n",
    "    sys.stdout = orig_stdout\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The user's most preferred configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(xstar_unscaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find parametric priors that are in KL-sense closest to the expert's opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from priorelicitation import Prior, g_theta, minimize_KL, sample_h, plot\n",
    "from random_fourier_sampler import Hsampler\n",
    "from scipy.stats import norm, beta\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sampler = Hsampler(GP_model)\n",
    "h_sampler.generate_basis()\n",
    "h_sampler.update_phi_X()\n",
    "h_sampler.update_omega_MAP()\n",
    "h_sampler.update_covariancematrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sample=[]\n",
    "for i in range(1000):\n",
    "    lambda_sample.append(GP_model.FP.unscale(h_sampler.sample_xstar()))\n",
    "lambda_sample = np.array(lambda_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_hyperparams = [0.2,0.2,0.2,0.2,1.5,0.375,0.1] #Scale parameters of the priors\n",
    "prior0 = Prior(family='beta',valrange=(0,1),lambda_indices=[0],fixed_hyperparams=[fixed_hyperparams[0]],is_location_param=True)\n",
    "prior1 = Prior(family='beta',valrange=(0,1),lambda_indices=[1],fixed_hyperparams=[fixed_hyperparams[1]],is_location_param=True) \n",
    "prior2 = Prior(family='beta',valrange=(0,1),lambda_indices=[2],fixed_hyperparams=[fixed_hyperparams[2]],is_location_param=True) \n",
    "prior3 = Prior(family='beta',valrange=(0,1),lambda_indices=[3],fixed_hyperparams=[fixed_hyperparams[3]],is_location_param=True) \n",
    "prior4 = Prior(family='normal',valrange=(2,15),lambda_indices=[4],fixed_hyperparams=[fixed_hyperparams[4]],is_location_param=True) \n",
    "prior5 = Prior(family='normal',valrange=(0.25,3),lambda_indices=[5],fixed_hyperparams=[fixed_hyperparams[5]],is_location_param=True) \n",
    "prior6 = Prior(family='beta',valrange=(0,1),lambda_indices=[6],fixed_hyperparams=[fixed_hyperparams[6]],is_location_param=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_hyperparameters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior0: Beta(x,0.2) for parameter $\\rho_{Z}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior0.domain[0], prior0.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior0,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior0)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior0.fixed_hyperparams[0]),g,thetas,fig_id=10)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.977, prior0.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 10),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior1: Beta(x,0.2) for parameter $\\rho_{g}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior1.domain[0], prior1.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior1,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior1)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior1.fixed_hyperparams[0]),g,thetas,fig_id=11)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.957, prior1.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 10),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior2: Beta(x,0.2) for parameter $\\theta_{p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior2.domain[0], prior2.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior2,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior2)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior2.fixed_hyperparams[0]),g,thetas,fig_id=12)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.648, prior2.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 10),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior3: Beta(x,0.2) for parameter $\\theta_{w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior3.domain[0], prior3.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior3,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior3)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior3.fixed_hyperparams[0]),g,thetas,fig_id=13)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.649, prior3.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 10),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior4: N(x,1.5) for parameter inv_adj_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior4.domain[0], prior4.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior4,lambda_sample) for theta in thetas]\n",
    "q = norm.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior4)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior4.fixed_hyperparams[0]),g,thetas,fig_id=14)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 5.632, prior4.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 0.4),plt.xlim(-10, 30),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior5: N(x,0.375) for parameter $\\sigma_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior5.domain[0], prior5.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior5,lambda_sample) for theta in thetas]\n",
    "q = norm.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior5)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior5.fixed_hyperparams[0]),g,thetas,fig_id=15)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 1.267, prior5.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 1.5),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior6: Beta(x,0.1) for parameter $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior6.domain[0], prior6.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior6,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior6)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior6.fixed_hyperparams[0]),g,thetas,fig_id=16)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.504, prior6.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 10),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the hyperparameters obtained from the KL-minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dsge/optimal_hyperparameters.txt', 'w') as f:\n",
    "    f.write(str(optimal_hyperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Thank you for your effort! You can logout now.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
