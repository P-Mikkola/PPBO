{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projective Preferential Prior Elicitation: DSGE prior elicitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">In this notebook the expert knowledge about DSGE priors can be elicited by using the [Projective Preferential Bayesian Optimization](https://arxiv.org/abs/2002.03113) framework. The test case is a New Keynesian pre-crisis DSGE model from Smets and Wouters (2007) as it appears in (Fratto and Uhlig, 2019). </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"><font color=\"red\">**INSTRUCTIONS**:\n",
    "- Read [this](../files/dsge/docs/Instructions.pdf) first\n",
    "- Write your name within the apostrophe:</font> </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_NAME = 'PETRUS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"><font color=\"red\">\n",
    "- Click: 'Kernel' $\\rightarrow$ 'Restart & Run All' $\\rightarrow$ 'Restart and Run All Cells'\n",
    "- Scroll down to the cell below 'Elicitation loop' and wait until you can provide feedback\n",
    "- Wait and provide your feedback until 'Elicitation done!' is printed\n",
    "- Your input is no longer needed, thank you! However, please do not logout until 'Thank you for your effort!...' is printed.</font> </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.output_scroll { height: 60em; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.getcwd()+'/src')\n",
    "sys.path.insert(1, os.getcwd()+'/dsge')\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from gp_model import GPModel\n",
    "from ppbo_settings import PPBO_settings\n",
    "from acquisition import next_query\n",
    "from gui import GUI_session\n",
    "from jupyter_ui_poll import run_ui_poll_loop\n",
    "from ipywidgets.widgets import HBox\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 60em; }</style>\")) #Make outputwindow larger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the aquisition strategy and the problem setting\n",
    "Acquisition startegies with unit projections ($\\boldsymbol{\\xi}$ is an unit vector):\n",
    "- PCD = preferential coordinate descent\n",
    "- EI-EXT = same as EI-FIXEDX except only unit projections are allowed\n",
    "- EI-EXT-FAST = same as EI-EXT except $d\\mathbf{x}$ integral omitted\n",
    "- EI-VARMAX = same as EI-EXT except $\\mathbf{x}$ is chosen to maximize GP variance\n",
    "- EI-VARMAX-FAST = same as EI-VARMAX except $d\\mathbf{x}$ integral omitted\n",
    "\n",
    "Acquisition startegies with non-unit projections:\n",
    "- EI = expected improvement by projective preferential query\n",
    "- EI-FIXEDX = same as EI except $\\mathbf{x}$ is fixed to $\\textrm{argmax}_{\\mathbf{x}}\\mu(\\mathbf{x})$ (xstar)\n",
    "- EXT = pure exploitation\n",
    "- EXR = pure exploration (variance maximization)\n",
    "- RAND = random \n",
    "\n",
    "'user_feedback_grid_size' determines the granularity of the slider, that is, the number of options available for the user. Each option is run in a dedicated CPU. Hence, the optimal performance will be achieved if 'user_feedback_grid_size' is a multiple of the number of CPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_strategy = 'PCD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPBOset = PPBO_settings(D=7,bounds=((0.3,0.8),(0.4,0.9),(0.3,0.8),(0.3,0.8),(2,8),(0.5,3),(0.3,0.8)),\n",
    "                    xi_acquisition_function=acquisition_strategy,user_feedback_grid_size=15,\n",
    "                    theta_initial=[0.05,0.27,0.2],m=22,verbose=False,\n",
    "                    skip_computations_during_initialization=True)\n",
    "#[0.09,0.2,0.35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set initial queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_queries_xi = np.diag([PPBOset.original_bounds[i][1] for i in range(PPBOset.D)])\n",
    "initial_queries_x = np.random.uniform([PPBOset.original_bounds[i][0] for i in range(PPBOset.D)], [PPBOset.original_bounds[i][1] for i in range(PPBOset.D)], (len(initial_queries_xi), PPBOset.D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_QUERIES = 14\n",
    "ADAPTIVE_INITIALIZATION = True  #In initilization: immediatly update the coordinate according to the user feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZE_HYPERPARAMETERS_AFTER_EACH_ITERATION = False\n",
    "OPTIMIZE_HYPERPARAMETERS_AFTER_QUERY_NUMBER = 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the user session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_log = False\n",
    "if should_log:\n",
    "    orig_stdout = sys.stdout\n",
    "    log_file = open('dsge/user_session_log_'+str(SESSION_NAME)+'_'+str(datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))+'.txt', \"w\")\n",
    "    sys.stdout = log_file\n",
    "GUI_ses = GUI_session(PPBOset)\n",
    "results_mustar = []\n",
    "results_xstar = []\n",
    "results_xstar_unscaled = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elicitation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elicitation done!\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "for i in range(len(initial_queries_xi)+NUMBER_OF_QUERIES):\n",
    "    if i < len(initial_queries_xi):\n",
    "        print(f'Initialization in progress... ({i+1}/{len(initial_queries_xi)})\\r', end=\"\")\n",
    "        if i==len(initial_queries_xi)-1:\n",
    "            GP_model.turn_initialization_off()\n",
    "    else:\n",
    "        print(f'Elicitation in progress... ({i+1-len(initial_queries_xi)}/{NUMBER_OF_QUERIES})\\r', end=\"\")\n",
    "        if i+1==len(initial_queries_xi)+NUMBER_OF_QUERIES:\n",
    "            GP_model.set_last_iteration()\n",
    "    ''' Next projective preferential query '''\n",
    "    if i < len(initial_queries_xi):\n",
    "        xi = initial_queries_xi[i].copy()\n",
    "        if not i==0 and GUI_ses.user_feedback is not None and ADAPTIVE_INITIALIZATION:\n",
    "            initial_queries_x[i:,:] = GUI_ses.user_feedback\n",
    "        x = initial_queries_x[i].copy()\n",
    "        x[xi!=0] = 0\n",
    "    else:\n",
    "        xi,x = next_query(PPBOset,GP_model,unscale=True)\n",
    "    GUI_ses.set_x(x)\n",
    "    GUI_ses.set_xi(xi)\n",
    "    ''' Event loop '''\n",
    "    button,slider,fig,l1,l2,l3,l4 = GUI_ses.prepare_app()\n",
    "    app = HBox(children=(slider,button))\n",
    "    def wait_user_input():\n",
    "        if not GUI_ses.user_feedback_was_given:\n",
    "            GUI_ses.update_plot(l1,l2,l3,l4,fig,slider)  \n",
    "            return None\n",
    "        app.close()\n",
    "        GUI_ses.user_feedback_was_given = False\n",
    "        GUI_ses.save_results()\n",
    "        return 1       \n",
    "    display(app)\n",
    "    dt = run_ui_poll_loop(wait_user_input)\n",
    "    ''' Create GP model for first time '''\n",
    "    if i==0:\n",
    "        GP_model = GPModel(PPBOset)\n",
    "        GP_model.set_COVARIANCE_SHRINKAGE(1e-6)\n",
    "    ''' Update GP model '''\n",
    "    GP_model.update_feedback_processing_object(np.array(GUI_ses.results))\n",
    "    GP_model.update_data()\n",
    "    GP_model.update_model()\n",
    "    if i+1==OPTIMIZE_HYPERPARAMETERS_AFTER_QUERY_NUMBER:\n",
    "        GP_model.update_model(optimize_theta=True)     \n",
    "    else:\n",
    "        GP_model.update_model(optimize_theta=OPTIMIZE_HYPERPARAMETERS_AFTER_EACH_ITERATION)\n",
    "    ''' Save the predictive mean maximum and maximizer'''\n",
    "    results_mustar.append(GP_model.mustar)\n",
    "    results_xstar.append(GP_model.xstar)\n",
    "    results_xstar_unscaled.append(GP_model.FP.unscale(GP_model.xstar))\n",
    "    clear_output(wait=True)\n",
    "print(\"Elicitation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 417.1966915130615 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time: \" + str(time.time()-start) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the user session results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the user session results...\n"
     ]
    }
   ],
   "source": [
    "#Save results to csv-file\n",
    "print(\"Saving the user session results...\")\n",
    "user_session_results = GUI_ses.results.copy()\n",
    "user_session_results['iter_mustar'] = results_mustar\n",
    "user_session_results['iter_xstar'] = results_xstar\n",
    "user_session_results['iter_xstar_unscaled'] = results_xstar_unscaled\n",
    "user_session_results.to_csv('dsge/user_session_results_'+str(SESSION_NAME)+'_'+str(datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\"))+'.csv',index=False)\n",
    "#Close the log-file\n",
    "if should_log:\n",
    "    sys.stdout = orig_stdout\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The user's most preferred hyperprior configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred lambda: [0.3        0.40280499 0.3        0.3        2.         0.5\n",
      " 0.3       ]\n"
     ]
    }
   ],
   "source": [
    "print('Preferred lambda: ' + str(GP_model.FP.unscale(GP_model.xstar)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find parametric priors that are in KL-sense closest to the expert's opinion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from priorelicitation import Prior, g_theta, minimize_KL, sample_h, plot\n",
    "from random_fourier_sampler import Hsampler\n",
    "from scipy.stats import norm, beta\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sampler = Hsampler(GP_model)\n",
    "h_sampler.generate_basis()\n",
    "h_sampler.update_phi_X()\n",
    "h_sampler.update_omega_MAP()\n",
    "h_sampler.update_covariancematrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad omega sample: unable to find f_approx maximizer\n"
     ]
    }
   ],
   "source": [
    "lambda_sample=[]\n",
    "for i in range(1000):\n",
    "    lambda_sample.append(GP_model.FP.unscale(h_sampler.sample_xstar()))\n",
    "lambda_sample = np.array(lambda_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_hyperparams = [0.1,0.1,0.2,0.2,1.5,0.375,0.1] #Scale parameters of the priors\n",
    "prior0 = Prior(family='beta',valrange=(0,1),lambda_indices=[0],fixed_hyperparams=[fixed_hyperparams[0]],is_location_param=True)\n",
    "prior1 = Prior(family='beta',valrange=(0,1),lambda_indices=[1],fixed_hyperparams=[fixed_hyperparams[1]],is_location_param=True) \n",
    "prior2 = Prior(family='beta',valrange=(0,1),lambda_indices=[2],fixed_hyperparams=[fixed_hyperparams[2]],is_location_param=True) \n",
    "prior3 = Prior(family='beta',valrange=(0,1),lambda_indices=[3],fixed_hyperparams=[fixed_hyperparams[3]],is_location_param=True) \n",
    "prior4 = Prior(family='normal',valrange=(2,15),lambda_indices=[4],fixed_hyperparams=[fixed_hyperparams[4]],is_location_param=True) \n",
    "prior5 = Prior(family='normal',valrange=(0.25,3),lambda_indices=[5],fixed_hyperparams=[fixed_hyperparams[5]],is_location_param=True) \n",
    "prior6 = Prior(family='beta',valrange=(0,1),lambda_indices=[6],fixed_hyperparams=[fixed_hyperparams[6]],is_location_param=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_hyperparameters = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior0: Beta(x,0.1) for parameter $\\zeta_{w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior0.domain[0], prior0.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior0,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior0)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dfa79c68704587b310cdd7eda603a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior0.fixed_hyperparams[0]),g,thetas,fig_id=10)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.788, prior0.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 2.5),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior0_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior1: Beta(x,0.1) for parameter $\\zeta_{p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior1.domain[0], prior1.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior1,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior1)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c278bbcb6d45a69bfc0b5a03858c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior1.fixed_hyperparams[0]),g,thetas,fig_id=11)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.861, prior1.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 2.5),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior1_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior2: Beta(x,0.2) for parameter $\\theta_{p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior2.domain[0], prior2.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior2,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior2)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff90b57a6ab450882430b6d39acaf0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior2.fixed_hyperparams[0]),g,thetas,fig_id=12)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.648, prior2.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 2.5),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior2_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior3: Beta(x,0.2) for parameter $\\theta_{w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior3.domain[0], prior3.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior3,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior3)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338688848a0a411e9b62b98e87eb3872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior3.fixed_hyperparams[0]),g,thetas,fig_id=13)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.649, prior3.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 2.5),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior3_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior4: N(x,1.5) for parameter inv_adj_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior4.domain[0], prior4.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior4,lambda_sample) for theta in thetas]\n",
    "q = norm.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior4)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f763b999c6bb4c959ba5d39bd32ae59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior4.fixed_hyperparams[0]),g,thetas,fig_id=14)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 5.632, prior4.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 0.4),plt.xlim(-10, 30),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior4_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior5: N(x,0.375) for parameter $\\sigma_c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior5.domain[0], prior5.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior5,lambda_sample) for theta in thetas]\n",
    "q = norm.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior5)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6c361cc874448ebf45a8ff0753629e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior5.fixed_hyperparams[0]),g,thetas,fig_id=15)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 1.267, prior5.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 1.5),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior5_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior6: Beta(x,0.1) for parameter $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = np.arange(prior6.domain[0], prior6.domain[1], 0.01)\n",
    "g = [g_theta(theta,prior6,lambda_sample) for theta in thetas]\n",
    "q = beta.pdf\n",
    "opt_hyperparam = minimize_KL(q,g,prior6)\n",
    "optimal_hyperparameters.append(opt_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c55d82135b14469bb941840e674d874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot parametric and non-parametric priors elicited from the user\n",
    "plot(q(thetas, opt_hyperparam, prior6.fixed_hyperparams[0]),g,thetas,fig_id=16)\n",
    "#Plot true target (posterior estimated on the extended sample 1984-2015)\n",
    "plt.plot(thetas, q(thetas, 0.504, prior6.fixed_hyperparams[0]), c='green')\n",
    "plt.ylim(0, 1),plt.legend(['elicited parametric','elicited non-parametric','target']);\n",
    "plt.savefig('dsge/prior6_'+str(SESSION_NAME)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the hyperparameters obtained from the KL-minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dsge/optimal_hyperparameters_'+str(SESSION_NAME)+'.txt', 'w') as f:\n",
    "    f.write(str(optimal_hyperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for your effort! You can logout now.\n"
     ]
    }
   ],
   "source": [
    "print('Thank you for your effort! You can logout now.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
